{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object_Detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPg1SmMI4gdynU8EPjBV6u2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CGTo5V_wQ9Gh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620660034983,"user_tz":-60,"elapsed":6318,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"370c21db-764f-4b33-ab97-5ba426c9d45b"},"source":["!pip install tensorflow==1.15.0\n","!pip install tensorflow-object-detection-api\n","#!pip install tensorflow-gpu==1.15\n","#!pip install tf_slim\n","#!pip install tf-models-official\n","#!pip install tensorflow-estimator==1.15.*"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (56.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n","Requirement already satisfied: tensorflow-object-detection-api in /usr/local/lib/python3.7/dist-packages (0.1.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.36.2)\n","Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n","Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.1.2)\n","Requirement already satisfied: twine in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.4.1)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n","Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.22)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.12.4)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.1)\n","Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.41.1)\n","Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (0.9.1)\n","Requirement already satisfied: colorama>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (0.4.4)\n","Requirement already satisfied: pkginfo>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (1.7.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (2.23.0)\n","Requirement already satisfied: rfc3986>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (1.5.0)\n","Requirement already satisfied: readme-renderer>=21.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (29.0)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (3.10.1)\n","Requirement already satisfied: keyring>=15.1 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (23.0.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.32.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.0.8)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.12.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.15.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (56.1.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.3)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.1.0)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2020.12.5)\n","Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.17)\n","Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (2.6.1)\n","Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (3.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.7.4.3)\n","Requirement already satisfied: SecretStorage>=3.2; sys_platform == \"linux\" in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (3.3.1)\n","Requirement already satisfied: jeepney>=0.4.2; sys_platform == \"linux\" in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (0.6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow->tensorflow-object-detection-api) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (1.0.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.0.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.1.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (4.7.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.9.4)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (1.9.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (22.0.3)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (1.0.18)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.4.3)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine->tensorflow-object-detection-api) (20.9)\n","Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (3.4.7)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.5)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (2.20)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sexjqk336o_9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620660038641,"user_tz":-60,"elapsed":2354,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"c36b97e6-8d34-480c-c92e-977aa0574349"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Umimv_rBI4P","executionInfo":{"elapsed":1061,"status":"ok","timestamp":1619467840081,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"2a8164c2-c63c-448d-fd55-a8843c0f883c"},"source":["\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lrnxO6-T-7ku","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620660061728,"user_tz":-60,"elapsed":21493,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"96d0c937-fdea-4869-818f-f4adf4e979f2"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G98tBlgU5-By","executionInfo":{"status":"ok","timestamp":1620038158900,"user_tz":-60,"elapsed":982,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"3f5ee382-df02-4389-a399-87ea18321c9c"},"source":["model_dir = '/content/drive/MyDrive/MLiSP2/Object_Detection/Model'\n","#!rm -rf '{model_dir}'\n","#os.makedirs(model_dir, exist_ok=True)\n","!ls -ltra '{model_dir}'/.."],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 75131\n","drwx------ 2 root root     4096 Apr 22 10:37 Test_imgs\n","drwx------ 2 root root     4096 Apr 25 10:48 Model\n","drwx------ 2 root root     4096 Apr 25 15:16 Model_2\n","-rw------- 1 root root 73665307 Apr 26 20:05 train.record\n","-rw------- 1 root root      474 Apr 26 20:05 labelmap.pbtxt\n","-rw------- 1 root root  2028100 Apr 26 20:05 test.record\n","-rw------- 1 root root     4070 Apr 28 18:22 pipeline.config\n","-rw------- 1 root root  1222849 May  3 10:35 Object_Detection.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XNamJzM80Tjn"},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/dctian/DeepPiCar'\n","\n","# Number of training steps.\n","num_steps = 30000  # 200000\n","#num_steps = 100  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","\n","# model configs are from Model Zoo github: \n","# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n","MODELS_CONFIG = {\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n","    'ssd_mobilenet_v1_quantized': {\n","        'model_name': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18',\n","        'pipeline_file': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync.config',\n","        'batch_size': 12\n","    },    \n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","    'ssd_mobilenet_v2_quantized': {\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","# Note: for Edge TPU, you have to:\n","# 1) start with a pretrained model from model zoo, such as above 4\n","# 2) Must be a quantized model, which reduces the model size significantly\n","selected_model = 'ssd_mobilenet_v2_quantized'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuvyF2mc0mfv","executionInfo":{"elapsed":1146,"status":"ok","timestamp":1619693282915,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"dd664e90-df08-4435-9ffc-d53aeb0edcd5"},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","\n","print('Pull it so that we have the latest code/data')\n","!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'DeepPiCar' already exists and is not an empty directory.\n","/content/DeepPiCar\n","Pull it so that we have the latest code/data\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5aGZ5FtCoyq","executionInfo":{"elapsed":637,"status":"ok","timestamp":1619693286496,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"b7e93647-6bed-4e49-9ad1-54e05bc5b8c0"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["doc  driver  LICENSE  models  README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"Akl_gY2w0uiU","executionInfo":{"status":"error","timestamp":1620425433851,"user_tz":-60,"elapsed":10044,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"1118ee92-8c08-4c69-fc2f-8f1b7cc48d3e"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","^C\n","^C\n","[Errno 2] No such file or directory: '/content/models/research'\n","/content\n","object_detection/protos/*.proto: No such file or directory\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-f434266baaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONPATH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m':/content/models/research/:/content/models/research/slim/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python object_detection/builders/model_builder_test.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   result = _run_command(\n\u001b[0;32m--> 447\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    448\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m           \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m           \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m           close_fds=True)\n\u001b[0m\u001b[1;32m    196\u001b[0m       \u001b[0;31m# The child PTY is only needed by the spawned process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0merrpipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m                     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m                     \u001b[0merrpipe_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8fFEP9g0xuV","executionInfo":{"elapsed":8202,"status":"ok","timestamp":1619693299159,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"2463b2ce-dcd4-4307-a568-c89651187308"},"source":["%cd {repo_dir_path}/models/object_detection\n","\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python code/xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python code/xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python code/generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python code/generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/DeepPiCar/models/object_detection\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0429 10:48:14.936444 140407930324864 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 10:48:14.943957 140407930324864 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/DeepPiCar/models/object_detection/data/annotations/train.record\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0429 10:48:17.975683 140386053134208 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 10:48:17.981145 140386053134208 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/DeepPiCar/models/object_detection/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KF846be_1MIr"},"source":["test_record_fname = '/content/drive/MyDrive/MLiSP2/Object_Detection/test.record'\n","train_record_fname = '/content/drive/MyDrive/MLiSP2/Object_Detection/train.record'\n","label_map_pbtxt_fname = '/content/drive/MyDrive/MLiSP2/Object_Detection/labelmap.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"AhKHGMKm1cUW","executionInfo":{"elapsed":9183,"status":"error","timestamp":1619693303693,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"7fc66b47-6871-4230-b6ec-063ec3a745d8"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/models/research'\n","/content/DeepPiCar/models/object_detection\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1a340e977a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03' -> '/content/models/research/pretrained_model'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIHMneUx1he2","executionInfo":{"elapsed":1298,"status":"ok","timestamp":1619634131545,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"afb274ee-849d-4bb4-8e99-0c4ea3f95201"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 204M\n","drwx------  2 303230 5000 4.0K Jan  4  2019 .\n","drwxr-xr-x 23 root   root 4.0K Apr 28 18:22 ..\n","-rw-------  1 303230 5000  93M Jan  4  2019 model.ckpt.data-00000-of-00001\n","-rw-------  1 303230 5000  68K Jan  4  2019 model.ckpt.index\n","-rw-------  1 303230 5000  20M Jan  4  2019 model.ckpt.meta\n","-rw-------  1 303230 5000 4.3K Jan  4  2019 pipeline.config\n","-rw-------  1 303230 5000  24M Jan  4  2019 tflite_graph.pb\n","-rw-------  1 303230 5000  68M Jan  4  2019 tflite_graph.pbtxt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Zmy4twS21jnH","executionInfo":{"elapsed":1272,"status":"ok","timestamp":1619634131546,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"f2ff1e9b-a494-44f5-be61-8b6ac1da58a2"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"WXF60nRd1nRN"},"source":["import os\n","pipeline_fname = \"/content/drive/MyDrive/MLiSP2/Object_Detection/pipeline.config\"\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"To1Teby21tNV"},"source":["import re\n","\n","# training pipeline file defines:\n","# - pretrain model path\n","# - the train/test sets\n","# - ID to Label mapping and number of classes\n","# - training batch size\n","# - epochs to trains\n","# - learning rate\n","# - etc\n","\n","# note we just need to use a sample one, and make edits to it.\n","\n","num_classes = 6\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint: downloaded pre-trained model checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test, we created earlier with our training/test sets\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path: ID to label file\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps (Number of epochs to train)\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBwVR9bf10NT","executionInfo":{"elapsed":1066,"status":"ok","timestamp":1619693190948,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"5211b78f-bb9e-4fa6-c85c-4a444f13f480"},"source":["%cd /content/drive/MyDrive/MLiSP2/Object_Detection/\n","!ls\n","!cat {label_map_pbtxt_fname}\n","#%cd /content/models/research"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/MLiSP2/Object_Detection\n","labelmap.pbtxt\tModel_2\t\t\tpipeline.config  test.record\n","Model\t\tObject_Detection.ipynb\tTest_imgs\t train.record\n","item {\n","    name: \"box\",\n","    id: 1,\n","    display_name: \"box\"\n","}\n","item {\n","    name: \"left_turn\",\n","    id: 2,\n","    display_name: \"left_turn\"\n","}\n","item {\n","    name: \"person\",\n","    id: 3,\n","    display_name: \"person\"\n","}\n","item {\n","    name: \"right_turn\",\n","    id: 4,\n","    display_name: \"right_turn\"\n","}\n","item {\n","    name: \"traffic_light_down_green\",\n","    id: 5,\n","    display_name: \"traffic_light_down_green\"\n","}\n","item {\n","    name: \"traffic_light_up_red\",\n","    id: 6,\n","    display_name: \"traffic_light_up_red\"\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfxQ9xLO17UN","executionInfo":{"status":"ok","timestamp":1619881877987,"user_tz":-60,"elapsed":852,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"53ff21ca-e61e-4fb9-a4cd-751bf4b2d89c"},"source":["!cat {pipeline_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cat: {pipeline_fname}: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jP_7QSsF5qqC","executionInfo":{"elapsed":3993,"status":"ok","timestamp":1619468987144,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"},"user_tz":-60},"outputId":"c68c52cd-a5bf-499c-a063-3aabd6d46a65"},"source":["!pip install lvis"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.22)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lwZTHT5u3jkY"},"source":["# TRAINING\n","num_steps = 30000\n","#SendEmail(\"Colab train started\")\n","!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir='{model_dir}' \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}\n","#SendEmail(\"Colab train finished\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3CbCdk93ej4","executionInfo":{"status":"ok","timestamp":1620038176283,"user_tz":-60,"elapsed":487,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"0a4da482-3220-4360-9f46-42d5903e34da"},"source":["!ls -ltra '{model_dir}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 534255\n","-rw------- 1 root root 30108647 Apr 26 20:30 graph.pbtxt\n","drwx------ 2 root root     4096 Apr 26 20:41 eval_0\n","-rw------- 1 root root    68804 Apr 26 23:21 model.ckpt-24859.index\n","-rw------- 1 root root 75237296 Apr 26 23:21 model.ckpt-24859.data-00000-of-00001\n","-rw------- 1 root root 16341516 Apr 26 23:21 model.ckpt-24859.meta\n","-rw------- 1 root root    68804 Apr 26 23:31 model.ckpt-26308.index\n","-rw------- 1 root root 75237296 Apr 26 23:31 model.ckpt-26308.data-00000-of-00001\n","-rw------- 1 root root 16341516 Apr 26 23:31 model.ckpt-26308.meta\n","-rw------- 1 root root    68804 Apr 26 23:41 model.ckpt-27755.index\n","-rw------- 1 root root 75237296 Apr 26 23:41 model.ckpt-27755.data-00000-of-00001\n","-rw------- 1 root root 16341516 Apr 26 23:41 model.ckpt-27755.meta\n","-rw------- 1 root root    68804 Apr 26 23:51 model.ckpt-29207.index\n","-rw------- 1 root root 75237296 Apr 26 23:51 model.ckpt-29207.data-00000-of-00001\n","-rw------- 1 root root 16341516 Apr 26 23:51 model.ckpt-29207.meta\n","-rw------- 1 root root    68804 Apr 26 23:56 model.ckpt-30000.index\n","-rw------- 1 root root 75237296 Apr 26 23:56 model.ckpt-30000.data-00000-of-00001\n","-rw------- 1 root root 16341516 Apr 26 23:56 model.ckpt-30000.meta\n","-rw------- 1 root root      277 Apr 26 23:57 checkpoint\n","drwx------ 2 root root     4096 Apr 26 23:57 export\n","-rw------- 1 root root 58712074 Apr 26 23:57 events.out.tfevents.1619469031.ad74b2b3f526\n","drwx------ 2 root root     4096 Apr 27 09:00 fine_tuned_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bVUfiyWkJMlg"},"source":["lst = os.listdir(model_dir)\n","# find the last model checkpoint file, i.e. model.ckpt-1000.meta\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZcQQKnuJOVi"},"source":["!echo creates the frozen inference graph in fine_tune_model\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzUE7LW-Jdcr"},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ds9rM5uFJfhH"},"source":["!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_quantized.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GC7CZlbOiCFY"},"source":["def region_of_interest(img, vertices):\n","    # Define a blank matrix that matches the image height/width.\n","    mask = np.zeros_like(img)\n","    # Retrieve the number of color channels of the image.\n","    channel_count = 3\n","    # Create a match color with the same color channel counts.\n","    match_mask_color = (255,) * channel_count\n","      \n","    # Fill inside the polygon\n","    cv.fillPoly(mask, vertices, match_mask_color)\n","    \n","    # Returning the image only where mask pixels match\n","    masked_image = cv.bitwise_and(img, mask)\n","    return masked_image\n","\"\"\"\n","def region_of_interest(img):\n","    height, width = img.shape[0], img.shape[1]\n","    mask = np.zeros_like(img)\n","\n","    # only focus bottom half of the screen\n","    polygon = np.array([[\n","        (0, height * 2 / 3),\n","        (width, height * 2 / 3),\n","        (width, height),\n","        (0, height),\n","    ]], np.int32)\n","\n","    cv.fillPoly(mask, polygon, 255)\n","    cropped_edges = cv.bitwise_and(img, mask)\n","    return cropped_edges\n","\"\"\"\n","\n","def get_line_values(img):\n","  region_of_interest_vertices = [\n","      (0, img.shape[0]),\n","      (img.shape[1] / 2, img.shape[0] / 2),\n","      (img.shape[1], img.shape[0]),\n","  ]\n","\n","  gray_image = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n","  # Call Canny Edge Detection here.\n","  cannyed_image = cv.Canny(gray_image, 100, 200)\n","\n","  #cropped_image = region_of_interest(\n","  #    cannyed_image)\n","\n","  cropped_image = region_of_interest(\n","    cannyed_image,\n","    np.array(\n","        [region_of_interest_vertices],\n","        np.int32\n","     ),\n","  )\n","  lines = cv.HoughLinesP(\n","      cropped_image,\n","      rho=6,#6\n","      theta=np.pi / 30,#30\n","      threshold=30, #40\n","      lines=np.array([]),\n","      minLineLength=40, #15\n","      maxLineGap=5 #5\n","  )\n","  if lines is None:\n","    return [[0, 0, 0, 0]]\n","  lines_list = []\n","  for i in lines:\n","    for ii in i:\n","        x1, y1, x2, y2  = ii\n","        lines_list.append([x1, y1, x2, y2 ])\n","\n","  return lines_list\n","\n","def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n","  # If there are no lines to draw, exit.\n","  if lines is None:\n","      return\n","  # Make a copy of the original image.\n","  img = np.copy(img)\n","  # Create a blank image that matches the original in size.\n","  line_img = np.zeros(\n","      (\n","          img.shape[0],\n","          img.shape[1],\n","          3\n","      ),\n","      dtype=np.uint8,\n","  )\n","  # Loop over all lines and draw them on the blank image.\n","  for i in lines:\n","          x1, y1, x2, y2  = i\n","          cv.line(line_img, (x1, y1), (x2, y2), color, thickness)\n","          \n","  # Merge the image with the lines onto the original.\n","  img = cv.addWeighted(img, 0.8, line_img, 1.0, 0.0)\n","  # Return the modified image.\n","  return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1MC_ugjiFmh"},"source":["\n","lines = np.asarray(get_line_values(test_images[449]))\n","print(lines)\n","line_image = draw_lines(test_images[449], lines)\n","plt.imshow(line_image)\n","\"\"\"\n","avg_lines = []\n","for i in range(lines.shape[1]):\n","  sum = 0\n","  for ii in range(lines.shape[0]):\n","    sum +=  lines[ii][i]\n","  avg_lines.append(sum / lines.shape[0])\n","\"\"\"\n","\n","x1, y1, x2, y2 = np.median(lines[:,0]),np.median(lines[:,1]),np.median(lines[:,2]),np.median(lines[:,3])\n","print(x1, y1, x2, y2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Jn5lbxEOrmX"},"source":["\"\"\"\n","turn_threshold = 40 #40...\n","def get_turn_value(turn_list ,direction):\n","    print(\"Using Object Detection for angle detection\")\n","    if (turn_list[0][0] - turn_list[0][1]) >= turn_threshold and (turn_list[0][0] - turn_list[0][1]) < turn_threshold+10: \n","      angle_value = 0.4 \n","    elif (turn_list[0][0] - turn_list[0][1]) >= turn_threshold+10 and (turn_list[0][0] - turn_list[0][1]) < turn_threshold+20: \n","      angle_value = 0.3  \n","    elif (turn_list[0][0] - turn_list[0][1]) >= turn_threshold+20 and (turn_list[0][0] - turn_list[0][1]) < turn_threshold+30: \n","      angle_value = 0.2  \n","    elif (turn_list[0][0] - turn_list[0][1]) >= turn_threshold+30 and (turn_list[0][0] - turn_list[0][1]) < turn_threshold+40: \n","      angle_value = 0.1 \n","    elif (turn_list[0][0] - turn_list[0][1]) >= turn_threshold+40:  \n","       angle_value = 0\n","    else:\n","      angle_value = 0.5\n","\n","    if direction == \"right\":\n","      return 1 - angle_value\n","    else:\n","      return angle_value\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS-Te55lH4ks","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1620915668343,"user_tz":-60,"elapsed":93018,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"a7effe49-2cdc-4cbd-afb5-3db13f624ab7"},"source":["!pip install tensorflow==1.15.0\n","!pip install tensorflow-object-detection-api\n","#!pip install tensorflow-gpu==1.15\n","#!pip install tf_slim\n","#!pip install tf-models-official\n","#!pip install tensorflow-estimator==1.15.*"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     || 412.3MB 28kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     || 3.8MB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     || 512kB 50.0MB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     || 51kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (56.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=df598b731bf336f74a0f35238a4fc2ae5af0c614ed8c076b360d458248248f99\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorboard, tensorflow-estimator, keras-applications, tensorflow\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting tensorflow-object-detection-api\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/11/7f6d3c5c4b603cc40b2813059779afb641bd5eb68045c62ca520bfce0359/tensorflow_object_detection_api-0.1.1.tar.gz (577kB)\n","\u001b[K     || 583kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.1.2)\n","Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n","Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.23)\n","Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.12.4)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.36.2)\n","Collecting twine\n","  Downloading https://files.pythonhosted.org/packages/42/ad/713372978a8de58a43c507bf62b9c30c3d7b5cda4e972d563b881620a511/twine-3.4.1-py3-none-any.whl\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.7)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (56.1.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.1.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.32.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.0.8)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.15.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.2)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.15.0)\n","Collecting keyring>=15.1\n","  Downloading https://files.pythonhosted.org/packages/26/f9/41230ac47f738f1ba66676dc8d3b30ca5b1f9eb0230fc204bcd9836c4ae9/keyring-23.0.1-py3-none-any.whl\n","Collecting rfc3986>=1.4.0\n","  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.41.1)\n","Collecting readme-renderer>=21.0\n","  Downloading https://files.pythonhosted.org/packages/39/a5/459adfa22ea237f6e8d0fa95ad29d7369579a5eec26f016ab34bb7f8359c/readme_renderer-29.0-py2.py3-none-any.whl\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (2.23.0)\n","Collecting requests-toolbelt!=0.9.0,>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n","\u001b[K     || 61kB 4.0MB/s \n","\u001b[?25hCollecting pkginfo>=1.4.2\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/d78e7c299eb5659bc3a036e5a968a399c62bfe0b2aa18baf7d13f43373ba/pkginfo-1.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.0.1)\n","Collecting colorama>=0.4.3\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.0.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.5.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (4.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.1.3)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.9.4)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (1.0.18)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (1.9.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (22.0.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.4.3)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow->tensorflow-object-detection-api) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (1.0.1)\n","Collecting SecretStorage>=3.2; sys_platform == \"linux\"\n","  Downloading https://files.pythonhosted.org/packages/d9/1e/29cd69fdac7391aa51510dfd42aa70b4e6a826c8cd019ee2a8ab9ec0777f/SecretStorage-3.3.1-py3-none-any.whl\n","Collecting jeepney>=0.4.2; sys_platform == \"linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/b0/a6ea72741aaac3f37fb96d195e4ee576a103c4c04e279bc6b446a70960e1/jeepney-0.6.0-py3-none-any.whl (45kB)\n","\u001b[K     || 51kB 3.9MB/s \n","\u001b[?25hRequirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.17.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.7.4.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (2.6.0)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (20.9)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n","Collecting cryptography>=2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n","\u001b[K     || 3.2MB 10.1MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (2.20)\n","Building wheels for collected packages: tensorflow-object-detection-api\n","  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-cp37-none-any.whl size=844515 sha256=af040e13b4888d0ebd493d0dc6b9d98b3e06bd8b49f5df7d7a53d617610bdf3a\n","  Stored in directory: /root/.cache/pip/wheels/4a/54/d0/cfca11930c4b2025d40dede77059094070a67cc3e7bd3b285f\n","Successfully built tensorflow-object-detection-api\n","Installing collected packages: cryptography, jeepney, SecretStorage, keyring, rfc3986, readme-renderer, requests-toolbelt, pkginfo, colorama, twine, tensorflow-object-detection-api\n","Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-3.4.7 jeepney-0.6.0 keyring-23.0.1 pkginfo-1.7.0 readme-renderer-29.0 requests-toolbelt-0.9.1 rfc3986-1.5.0 tensorflow-object-detection-api-0.1.1 twine-3.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nK4k27nmpd3q"},"source":[""]},{"cell_type":"code","metadata":{"id":"GqCCW2ARKa8W","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"error","timestamp":1620915563545,"user_tz":-60,"elapsed":3630,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"54d84a47-69cd-47e1-bc39-af765f037348"},"source":["#%reset\n","#%matplotlib inline\n","import cv2 as cv\n","import numpy as np\n","from shapely.geometry import Polygon\n","import os\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","from tensorflow.keras.models import load_model\n","import shapely.geometry \n","import descartes\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c6b7e73716f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"Z6kXAj_8Xw_A","executionInfo":{"status":"aborted","timestamp":1620915563541,"user_tz":-60,"elapsed":3022,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}}},"source":["print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYLW5F7NOHqE","executionInfo":{"status":"aborted","timestamp":1620915563542,"user_tz":-60,"elapsed":2301,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-c_HNwaMtgY","executionInfo":{"status":"aborted","timestamp":1620915563543,"user_tz":-60,"elapsed":1647,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}}},"source":["test_images = np.asarray(np.load(\"/content/drive/MyDrive/MLiSP2/Holdout_Channels/Holdout_RGB_Not_Resized.pkl\",allow_pickle=True))\n","print(test_images.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TNNTfeapsOT","executionInfo":{"status":"aborted","timestamp":1620915563544,"user_tz":-60,"elapsed":765,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}}},"source":["num_classes = 6\n","model_dir = '/content/drive/MyDrive/MLiSP2/Object_Detection/Model'\n","output_directory = '%s/fine_tuned_model' % model_dir\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\") \n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(pb_fname, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map_pbtxt_fname = '/content/drive/MyDrive/MLiSP2/Object_Detection/labelmap.pbtxt'\n","label_map = label_map_util.load_labelmap(label_map_pbtxt_fname)\n","categories = label_map_util.convert_label_map_to_categories(\n","label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uP2evDMKfAo","executionInfo":{"status":"ok","timestamp":1620915565186,"user_tz":-60,"elapsed":480,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}}},"source":["def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"9gfWQzKpL33I","executionInfo":{"status":"error","timestamp":1620915566893,"user_tz":-60,"elapsed":484,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"845aa412-1eee-4283-97f2-a86a7c3f8548"},"source":["#!pip install keras==2.3.0\n","%cd /content/drive/MyDrive/MLiSP2/\n","model = load_model(\"Angle_Model.h5\")\n","#temp_X_test = np.load(\"X_test_temp.npy\")[:200]\n","#temp_y_test = np.load(\"y_test_temp.npy\")[:200]\n","\n","#temp = []\n","#for i in temp_X_test:\n","#  img = cv.resize(i, (320, 240))\n","#  temp.append(img)\n","#temp_X_test = np.asarray(temp)\n","#print(temp_X_test.shape)\n","#print(temp_y_test.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/MLiSP2/'\n","/content\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-603c5c554ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!pip install keras==2.3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/drive/MyDrive/MLiSP2/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Angle_Model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#temp_X_test = np.load(\"X_test_temp.npy\")[:200]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#temp_y_test = np.load(\"y_test_temp.npy\")[:200]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"IE-6qd4TcNwq"},"source":["def placehold(coordinates, object_detect):\n","  xmax, xmin, ymax, ymin = object_detect\n","  detaction_box = Polygon([[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]])\n","  region_of_interest = Polygon([[coordinates[0], coordinates[1] ], [coordinates[2], coordinates[3]], [coordinates[4], coordinates[5]]])\n","  find_intersection = detaction_box.intersection(region_of_interest)\n","  overlap = find_intersection.area\n","  return overlap, find_intersection"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wPHbFnBWTHe"},"source":["def turn(turn_cord, direction, multiplier=0.008):\n","  ymax, ymin = turn_cord[0]\n","  difference = ymax - ymin\n","\n","  if direction == \"left\":\n","    angle = 0.5 - (difference * multiplier)\n","    angle_amount = max(0, angle)\n","\n","  elif direction == \"right\":\n","    angle = 0.5 + (difference * multiplier)\n","    angle_amount = min(1, angle)\n","\n","  return abs(angle_amount)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMvwrfr4-g22"},"source":["def a_turn_f(turn_amount):\n","\n","  if turn_amount > 0.66 and turn_amount < 0.78: #right\n","    #number = turn_amount - 0.5\n","    x1 = 140  #Where x1 is the bottom left x value in the triangle\n","    y1 = 240\n","\n","    x2 = 320  #Where x2 is the middle x value in the triangle\n","    y2 = 80 # 120\n","\n","    x3 = 320\n","    y3 = 240\n","  elif turn_amount >= 0.78:\n","    x1 = 120  #Where x1 is the bottom left x value in the triangle\n","    y1 = 240\n","\n","    x2 = 320  #Where x2 is the middle x value in the triangle\n","    y2 = 180 # 120\n","\n","    x3 = 320\n","    y3 = 240\n","\n","  elif turn_amount <= 0.34: #left\n","    x1 = 0  #Where x1 is the bottom left x value in the triangle\n","    y1 = 240\n","\n","    x2 = 0  #Where x2 is the middle x value in the triangle\n","    y2 = 120 # 120\n","\n","    x3 = 160\n","    y3 = 240\n","  \n","  else:\n","    x1 = 0\n","    y1 = 240\n","\n","    x2 = 160\n","    y2 = 60\n","\n","    x3 = 320\n","    y3 = 240\n","\n","  return [x1, y1, x2, y2, x3, y3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoBnZm5xv6VY"},"source":["def predict_angle(model):\n","      img = cv.resize(test_images[n], (80, 60))  \n","      img_expanded = np.expand_dims(img, axis=0) \n","      img_expanded = img_expanded / 255. \n","      pred = model.predict(img_expanded)[0][0]\n","      return pred \n","      \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Cl7LfQOKlHz","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"error","timestamp":1620915556907,"user_tz":-60,"elapsed":976,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"f170f908-bf25-4ccd-c68f-e1870a3b8746"},"source":["%matplotlib inline\n","box_loc, person_loc, traffic_light_up_red_loc, speed, angle, left_turn_loc, right_turn_loc = [], [], [], [], [], [], []\n","classes = [\"box\",\n","           \"left_turn\", \n","           \"person\", \n","           \"right_turn\",\n","           \"traffic_light_down_green\",\n","           \"traffic_light_up_red\"]\n","\n","object_threshold = 0.5\n","person_threshold = [76, 64] # [76, 64]\n","box_threshold = 60 #60\n","traffic_light_red_threshold = 60  #60\n","\n","for i in range(test_images.shape[0]):\n","    # person --> 137 449 511 722 821 325\n","    # box --> 632 630 634 700 911 976\n","    # 260\n","    n = 149\n","\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(test_images[n], detection_graph)\n","\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        test_images[n],\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        min_score_thresh=object_threshold,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2)\n","\n","    #print(output_dict['detection_boxes'][:5])\n","    #print([i for i in output_dict['detection_scores'] if i > object_threshold])\n","    #for v in range(len(output_dict['detection_scores'])):\n","    #  if output_dict['detection_scores'][v] > object_threshold:\n","    #   print(classes[output_dict['detection_classes'][v]-1])\n","\n","    for ii in range(len(output_dict['detection_scores'])):\n","      if output_dict['detection_scores'][ii] >= object_threshold:\n","\n","        idx = output_dict['detection_classes'][ii] - 1\n","        current_class = classes[idx]\n","        ymin, xmin, ymax, xmax = output_dict['detection_boxes'][ii]\n","        width, height = 320, 240\n","        ymin, xmin, ymax, xmax = ymin * height, xmin * width, ymax * height, xmax * width\n","        if current_class == \"person\":\n","          person_loc.append([xmax, xmin, ymax, ymin])\n","        elif current_class == \"box\":\n","          box_loc.append([xmax, xmin, ymax, ymin])\n","        elif current_class == \"traffic_light_up_red\":\n","          traffic_light_up_red_loc.append([ymax, ymin])\n","        elif current_class == \"left_turn\":\n","          left_turn_loc.append([ymax, ymin])\n","        elif current_class == \"right_turn\":\n","          right_turn_loc.append([ymax, ymin])\n","\n","\n","        if left_turn_loc and len(angle) != (i + 1):\n","          angle.append(turn(left_turn_loc, direction = \"left\"))\n","        elif right_turn_loc and len(angle) != (i + 1):\n","          angle.append(turn(right_turn_loc, direction = \"right\"))\n","          \n","        if person_loc:\n","            if (person_loc[-1][0] - person_loc[-1][1] > person_threshold[0]) or (person_loc[-1][2] - person_loc[-1][3] > person_threshold[1]):\n","              #area_triangle = 9600*(2*angle[0] + 1)*(1 - angle[-1])\n","              #threshold_for_triangle = area_triangle * 300 / 9600\n","              if len(angle) != (i + 1):\n","                angle.append(predict_angle(model))\n","\n","              coordinates = a_turn_f(0.5)\n","              #print(person_loc[iii])\n","              area, _ = placehold(coordinates, person_loc[-1])\n","\n","              #print(f\"Area of trig: {area_triangle} | Threshold of trig: {threshold_for_triangle}\")\n","              #print(f\"Overlap Area: {area}\")\n","\n","              if area > 0 and len(speed) != (i + 1):\n","                speed.append(0)\n","                \n","      \n","        if box_loc and len(speed) != (i + 1):\n","          #print(f\"xmin: {box_loc[-1][1]}\\nxmax: {box_loc[-1][0]}\\nymin: {box_loc[-1][-1]}\\nymax: {box_loc[-1[2]}\")\n","          if (box_loc[-1][2] - box_loc[-1][3] > box_threshold):\n","            if len(angle) != (i + 1):\n","              angle.append(predict_angle(model))\n","              \n","            #area_triangle = 9600*(2*angle[-1] + 1)*(1 - angle[-1])\n","            #threshold_for_triangle = area_triangle * 300 / 9600\n","            coordinates = a_turn_f(angle[-1])\n","            #print(box_loc[-1])\n","            area, _ = placehold(coordinates, box_loc[-1])\n","            #print(f\"area of trig: {area_triangle} | threshold of trig: {threshold_for_triangle}\")\n","            #print(f\"Overlap Area: {area}\")\n","            if area > 0 and len(speed) != (i + 1):\n","              speed.append(0)\n","              \n","\n","        if traffic_light_up_red_loc and len(speed) != (i + 1):\n","          if (traffic_light_up_red_loc[0][0] - traffic_light_up_red_loc[0][1]  > traffic_light_red_threshold):\n","              speed.append(0)\n","              \n","      \n","\n","\n","\n","      traffic_light_up_red_loc.clear()\n","      box_loc.clear()\n","      person_loc.clear()\n","      left_turn_loc.clear()\n","      traffic_light_up_red_loc.clear()\n","      right_turn_loc.clear()\n","\n","    if len(angle) != (i + 1):\n","      angle.append(predict_angle(model))\n","    if len(speed) != (i + 1):\n","        speed.append(1)\n","\n","    print(f\"Speed: {speed} \\nAngle: {angle}\")\n","    #print(f\"Speed Size: {len(speed)} \\nAngle Size: {len(angle)}\")\n","    #print(coordinates)\n","    fig, ax = plt.subplots(1,1,figsize=(15,15))\n","    ax.plot([0, 160, 320, 0], [239, 60, 239, 239], color=\"red\", linewidth=3)\n","    #ax.plot([coordinates[0], coordinates[2], coordinates[4], coordinates[0]], [coordinates[1]-1, coordinates[3], coordinates[5]-1, coordinates[5]-1], color=\"red\", linewidth=3)\n","    ax.add_patch(descartes.PolygonPatch(_, fc='b', ec='k', alpha=0.2))\n","    #seg = draw_lines(test_images[n], get_line_values(test_images[n]))\n","    #ax.plot([0,160],[240, 120], color=\"blue\", linewidth=5)\n","    #ax.plot([160,320],[120, 240], color=\"blue\", linewidth=5)\n","    #ax.imshow(seg)\n","    ax.imshow(test_images[n])\n","    raise\n","    #if len(speed) == (i + 1) and len(angle) == (i+1):\n","      #break\n","\n","\n"," \n","\n","\n","        #if i % 100 == 0:\n","          #print(f\"Progress: {round((i + 1) / test_images.shape[0], 2)}%\")\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2929a63fd402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtraffic_light_red_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m  \u001b[0;31m#60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# person --> 137 449 511 722 821 325\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# box --> 632 630 634 700 911 976\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"]}]},{"cell_type":"code","metadata":{"id":"oHK6l32LJf3L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMLP3Bdtee7D","executionInfo":{"status":"ok","timestamp":1620295681914,"user_tz":-60,"elapsed":428,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"03697af3-9d1c-4858-fdf8-cda2038ccb8f"},"source":["%cd /content/drive/MyDrive/MLiSP2\n","speed_array = np.asarray(speed, dtype=int).reshape(-1, 1)\n","angle_array = np.asarray(angle, dtype=float).reshape(-1, 1)\n","\n","print(speed_array)\n","print(angle_array)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/MLiSP2\n","[[0]\n"," [1]\n"," [1]\n"," ...\n"," [1]\n"," [1]\n"," [1]]\n","[[0.5622493 ]\n"," [0.79927427]\n"," [0.32867193]\n"," ...\n"," [0.46162957]\n"," [0.        ]\n"," [0.24400452]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYrt6VGI4nFq","executionInfo":{"status":"ok","timestamp":1620295685568,"user_tz":-60,"elapsed":454,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"5a946c30-9b68-4192-90e2-6a82d583b28b"},"source":["angle_array.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1020, 1)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"87DlB9wm1CW1","executionInfo":{"status":"ok","timestamp":1620392575123,"user_tz":-60,"elapsed":739,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"e912e3d3-21da-4715-c1ed-ef87f1f1fe4b"},"source":["Polygon([[coordinates[0], 240-coordinates[1] ], [coordinates[2], 240-coordinates[3]], [coordinates[4], 240-coordinates[5]]])\n","#[[0, 0], [228.27447891235352, 68.79414081573486], [388.2744789123535, 0]]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<shapely.geometry.polygon.Polygon at 0x7fe5a7e25f90>"],"image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"205.60000000000002\" viewBox=\"-12.8 -12.8 345.6 205.60000000000002\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,180.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.3040000000000003\" opacity=\"0.6\" d=\"M 0.0,0.0 L 160.0,180.0 L 320.0,0.0 L 0.0,0.0 z\" /></g></svg>"},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"8tFsbPCH1w1l","executionInfo":{"status":"ok","timestamp":1620263348516,"user_tz":-60,"elapsed":538,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"7c907dd9-af8a-4134-a3e6-0a6f4f4f320d"},"source":["Polygon([[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<shapely.geometry.polygon.Polygon at 0x7f51cb5b6090>"],"image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"199.68702840805054 12.532814025878906 33.28482532501221 65.53158903121948\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,90.5972170829773)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"1.3106317806243897\" opacity=\"0.6\" d=\"M 202.1141242980957,14.959909915924072 L 230.54475784301758,14.959909915924072 L 230.54475784301758,75.63730716705322 L 202.1141242980957,75.63730716705322 L 202.1141242980957,14.959909915924072 z\" /></g></svg>"},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMCUhRpfXLB1","executionInfo":{"status":"ok","timestamp":1620295688567,"user_tz":-60,"elapsed":638,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"1f1f6dff-8460-4f53-a9d2-09c52936114b"},"source":["import pandas as pd\n","\n","columns = [\"image_id\", \"angle\", \"speed\"]\n","\n","image_id = np.asarray(range(1, test_images.shape[0] + 1)).reshape(-1, 1).astype(int)\n","\n","concat_columns = np.concatenate((image_id, angle_array, speed_array), axis=1)\n","results = pd.DataFrame(concat_columns, columns=columns)\n","\n","results[\"image_id\"] = results[\"image_id\"].astype(int)\n","results[\"speed\"] = results[\"speed\"].astype(int)\n","print(results)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["      image_id     angle  speed\n","0            1  0.562249      0\n","1            2  0.799274      1\n","2            3  0.328672      1\n","3            4  0.255977      1\n","4            5  0.075842      1\n","...        ...       ...    ...\n","1015      1016  0.497246      1\n","1016      1017  0.666625      0\n","1017      1018  0.461630      1\n","1018      1019  0.000000      1\n","1019      1020  0.244005      1\n","\n","[1020 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHvNnFcEiMLR","executionInfo":{"status":"ok","timestamp":1620295691265,"user_tz":-60,"elapsed":422,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"3e727b6b-b7ca-40b8-95f2-adb59818d9dd"},"source":["results[\"speed\"].value_counts()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    564\n","0    456\n","Name: speed, dtype: int64"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"1OSUCUv2WqZ1"},"source":["results.to_csv(\"/content/drive/MyDrive/MLiSP2/holdout_submission.csv\", header=True, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6jCtacs4Um0","executionInfo":{"status":"ok","timestamp":1620425543101,"user_tz":-60,"elapsed":456,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"462227c9-3f1e-4143-8bb9-627ef85dab5c"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: cd: /MyDrive: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPwKFLKa38ty","executionInfo":{"status":"ok","timestamp":1620426655992,"user_tz":-60,"elapsed":6857,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"916e3091-5b30-4fe2-858f-f0837c19724e"},"source":["!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'\n","\n","# create the tensorflow lite graph\n","!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true\n","\n","# CONVERTING frozen graph to quantized TF Lite file...\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_quantized.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops"],"execution_count":null,"outputs":[{"output_type":"stream","text":["python3: can't open file '/content/models/research/object_detection/export_inference_graph.py': [Errno 2] No such file or directory\n","python3: can't open file '/content/models/research/object_detection/export_tflite_ssd_graph.py': [Errno 2] No such file or directory\n","2021-05-07 22:30:51.284043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-05-07 22:30:51.295520: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-05-07 22:30:51.295590: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a9530f3e1da4): /proc/driver/nvidia/version does not exist\n","2021-05-07 22:30:51.296120: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2021-05-07 22:30:51.303868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2021-05-07 22:30:51.304160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a0d320ed80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-05-07 22:30:51.304199: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tflite_convert\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n","    app.run(main=run_main, argv=sys.argv[:1])\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n","    _convert_tf1_model(tflite_flags)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\n","    output_data = converter.convert()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/lite.py\", line 989, in convert\n","    **converter_kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 412, in toco_convert_graph_def\n","    enable_mlir_converter=enable_mlir_converter)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\n","    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n","tensorflow.lite.python.convert.ConverterError: See console for info.\n","2021-05-07 22:30:54.166509: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\n","2021-05-07 22:30:54.172130: F tensorflow/lite/toco/tooling_util.cc:1669] Check failed: input_array_dims[i] == input_array_proto.shape().dims(i) (300 vs. 240)\n","Fatal Python error: Aborted\n","\n","Current thread 0x00007f35587c9780 (most recent call first):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251 in _run_main\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303 in run\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40 in run\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\n","  File \"/usr/local/bin/toco_from_protos\", line 8 in <module>\n","Aborted (core dumped)\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkQSdmdU6Yxq","executionInfo":{"status":"ok","timestamp":1620425704355,"user_tz":-60,"elapsed":682,"user":{"displayName":"OJ L","photoUrl":"","userId":"12976686999064123497"}},"outputId":"73251537-8820-4793-e729-e1afde20a75f"},"source":["# download this file from google drive.\n","#%cd /content/gdrive/MyDrive/MLiSP2/Object_Detection/Model_2/fine_tuned_model/\n","\n","!ls -lt '/content/drive/MyDrive/MLiSP2/Object_Detection/Model/fine_tuned_model/road_signs_quantized.tflite'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw------- 1 root root 4793304 May  7 22:15 /content/drive/MyDrive/MLiSP2/Object_Detection/Model/fine_tuned_model/road_signs_quantized.tflite\n"],"name":"stdout"}]}]}